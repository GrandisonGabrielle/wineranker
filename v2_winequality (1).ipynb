{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d76d4597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2ed2b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "258de156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4      5.0  \n",
       "1      9.8      5.0  \n",
       "2      9.8      5.0  \n",
       "3      9.8      6.0  \n",
       "4      9.4      5.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('winequality-red.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4974177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c00c57ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality_binary'] = [1 if x >= 6 else 0 for x in df['quality']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa9d33e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>quality_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  quality_binary  \n",
       "0      9.4      5.0               0  \n",
       "1      9.8      5.0               0  \n",
       "2      9.8      5.0               0  \n",
       "3      9.8      6.0               1  \n",
       "4      9.4      5.0               0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12f69eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', \n",
    "'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', \n",
    "'sulphates', 'alcohol']].to_numpy()\n",
    "y=df[['quality_binary']].to_numpy()\n",
    "y = y.astype('float64')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0a55f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column-wise means: [ 8.31667724  0.52825618  0.27040583  2.53823716  0.08759163 15.8560558\n",
      " 46.36334813  0.996745    3.31135067  0.65826886 10.42355739]\n",
      "Column-wise standard deviations: [1.74283048e+00 1.79357701e-01 1.94873323e-01 1.41764613e+00\n",
      " 4.73236071e-02 1.04921484e+01 3.29199207e+01 1.89065013e-03\n",
      " 1.54728930e-01 1.70120577e-01 1.06235343e+00]\n"
     ]
    }
   ],
   "source": [
    "print('Column-wise means:', np.mean(x, axis=0))\n",
    "print('Column-wise standard deviations:', np.std(x, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b96057d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.scatter(df.index, df['fixed acidity'])\n",
    "plt.scatter(df.index, df['total sulfur dioxide'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c594894",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (x-np.mean(x, axis=0))/np.std(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8649e298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df.index, x[:,0])\n",
    "plt.scatter(df.index, x[:,6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5865071c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1577, 11)\n",
      "(1577, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d538454b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1261, 11) (1261, 1) (316, 11) (316, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, stratify=y)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a69baf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigmoid function \n",
    "def sigmoid(a):\n",
    "    x = 1/(1+np.exp(-a))\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51cdea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function \n",
    "#binary cross entropy loss \n",
    "\n",
    "def cross_entropy_loss(yhat, y): \n",
    "    l = np.mean(-y*np.log(yhat)-(1-y)*np.log(1-yhat))\n",
    "\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a2fb164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining w \n",
    "w = np.random.normal(0, 0.01, size = (x_train.shape[1],1))\n",
    "b = np.random.normal(0, 0.01, size = (1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec106b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matrix operation\n",
    "def perceptron(x, w, b):\n",
    "    #print(x.shape)\n",
    "    yhat = np.dot(x, w) + b\n",
    "    yhat = sigmoid(yhat)\n",
    "    \n",
    "    return yhat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dad9604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def compute_gradient (x, y, w, b):\n",
    "# m = no. of rows/data points, n = no. of colummns   \n",
    "   # m, n = x.shape\n",
    "# b = np.random.normal(0, 0.5, size = 1)\n",
    "    #dl_dw = np.zeros(w.shape)\n",
    "    #dl_db = 0.\n",
    "    #for i in range (m):\n",
    "     #   z_wb = 0\n",
    "      #  for l in range(n):\n",
    "       #     z_wb_il = w[l] * x[i,l]\n",
    "        #    z_wb += z_wb_il\n",
    "        #z_wb += b\n",
    "        #f_wb = sigmoid(z_wb)\n",
    "        #dl_db_i = f_wb - y[i]\n",
    "        #dl_db += dl_db_i\n",
    "        #for l in range(n):\n",
    "         #   dl_dw_il = (f_wb - y[i]) * x[i,l]\n",
    "          #  dl_dw[l] += dl_dw_il\n",
    "        \n",
    "    #dl_dw = dl_dw / m\n",
    "    #dl_db = dl_db / m\n",
    "       \n",
    "    #return dl_db, dl_dw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bc888e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#revised version\n",
    "#Compute the gradients: partial derivatives of the cost/loss are calculated to find the direction that minimises the loss function.\n",
    "\n",
    "def compute_gradient(x, y, w, b):\n",
    "    #print(x.shape)\n",
    "    m, n = x.shape \n",
    "    yhat = perceptron(x, w, b)\n",
    "    dw = np.dot(x.T, (yhat-y))/m\n",
    "    db = np.mean(yhat-y)\n",
    "    \n",
    "    return db, dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771b3705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def gradient_descent(x, y, w_in, b_in, loss_function, gradient_function, alpha, n_iters): \n",
    "    #m,n=x.shape\n",
    "    #m=len(x)\n",
    "    #l_history = []\n",
    "    #w_history = []\n",
    "    \n",
    "\n",
    "    #for i in range(n_iters):\n",
    "        #dl_db, dl_dw = compute_gradient(x, y, w_in, b_in, lambda_ = None)\n",
    "        #w_in = w_in - alpha * dl_dw\n",
    "        #b_in = b_in - alpha * dl_db\n",
    "        #loss = cross_entropy_loss(w_in, b_in)\n",
    "        #l_history.append(loss)\n",
    "   \n",
    "    #if i% math.ceil(n_iters/10) == 0 or i == (n_iters-1):\n",
    "        #w_history.append(w_in)\n",
    "        #print(f\"Iteration {i:4}: Cost {float(l_history[-1]):8.2f} \")\n",
    "    \n",
    "    #return w_in, b_in, l_history, w_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc6d32c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w, b, alpha, n): \n",
    "    for i in range(n): \n",
    "        #print(x.shape)\n",
    "        db, dw = compute_gradient(x, y, w, b)\n",
    "        w = w - alpha*dw\n",
    "        b = b - alpha*db\n",
    "        print('Loss:', cross_entropy_loss(perceptron(x, w, b), y))\n",
    "    return w, b #INDENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5095ba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, y, w, b):\n",
    "    #print(x.shape)\n",
    "    yhat = perceptron(x, w, b)\n",
    "    yhat = np.round(yhat) \n",
    "    z = y - yhat \n",
    "    abs_z = np.abs(z)\n",
    "    a = 1 - abs_z   #WAS 1-z --MISTAKE\n",
    "    accu = np.sum(a)/a.shape[0]\n",
    "    \n",
    "    return accu\n",
    "    \n",
    "    \n",
    " #   m, n = x.shape\n",
    "  #  p = np.zeros(m)\n",
    "   # b = np.random.normal(0, 0.5, size= 1)\n",
    "\n",
    "    #for i in range(m):\n",
    "     #   z_wb = 0\n",
    "      #  for l in range(n):\n",
    "          #  z_wb += x[i,l]*w[l]\n",
    "    #z_wb += b\n",
    "    #f_wb = sigmoid(z_wb)\n",
    "    #p[i] = np.round(f_wb)\n",
    "    \n",
    "    #count_corr = 0\n",
    "    #for i in range(m):\n",
    "     #   if p[i] == y[i]:\n",
    "      #      count_corr += 1\n",
    "    #return p,count_corr/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8dfe5745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6410998692470731\n",
      "Loss: 0.6079579058386431\n",
      "Loss: 0.5863304948788864\n",
      "Loss: 0.5715445379292703\n",
      "Loss: 0.5610074987934514\n",
      "Loss: 0.5532302862914229\n",
      "Loss: 0.5473190984686108\n",
      "Loss: 0.5427140546504093\n",
      "Loss: 0.5390507759725647\n",
      "Loss: 0.5360840675915115\n",
      "Loss: 0.5336440795915132\n",
      "Loss: 0.5316101433605795\n",
      "Loss: 0.5298946093721313\n",
      "Loss: 0.5284325521580298\n",
      "Loss: 0.5271750316319733\n",
      "Loss: 0.5260845742995494\n",
      "Loss: 0.5251320770383362\n",
      "Loss: 0.5242946442283295\n",
      "Loss: 0.5235540503471486\n",
      "Loss: 0.5228956297774248\n",
      "Loss: 0.5223074634962412\n",
      "Loss: 0.5217797753431562\n",
      "Loss: 0.5213044783766692\n",
      "Loss: 0.5208748301433451\n",
      "Loss: 0.52048516794891\n",
      "Loss: 0.5201307035628981\n",
      "Loss: 0.5198073625440787\n",
      "Loss: 0.5195116573975522\n",
      "Loss: 0.5192405866217931\n",
      "Loss: 0.5189915537418488\n",
      "Loss: 0.5187623018989883\n",
      "Loss: 0.5185508606439254\n",
      "Loss: 0.5183555023747116\n",
      "Loss: 0.5181747064509448\n",
      "Loss: 0.5180071294588472\n",
      "Loss: 0.5178515804365496\n",
      "Loss: 0.5177070001238738\n",
      "Loss: 0.5175724434964692\n",
      "Loss: 0.5174470649951664\n",
      "Loss: 0.5173301059788115\n",
      "Loss: 0.5172208840206675\n",
      "Loss: 0.5171187837407304\n",
      "Loss: 0.5170232489235166\n",
      "Loss: 0.5169337757164034\n",
      "Loss: 0.5168499067400549\n",
      "Loss: 0.5167712259717737\n",
      "Loss: 0.5166973542863325\n",
      "Loss: 0.5166279455580903\n",
      "Loss: 0.5165626832439291\n",
      "Loss: 0.5165012773794244\n",
      "Loss: 0.5164434619312882\n",
      "Loss: 0.5163889924578925\n",
      "Loss: 0.5163376440369696\n",
      "Loss: 0.5162892094256579\n",
      "Loss: 0.516243497423138\n",
      "Loss: 0.5162003314103649\n",
      "Loss: 0.5161595480449975\n",
      "Loss: 0.516120996092648\n",
      "Loss: 0.5160845353781537\n",
      "Loss: 0.5160500358427521\n",
      "Loss: 0.5160173766949014\n",
      "Loss: 0.5159864456440835\n",
      "Loss: 0.5159571382082841\n",
      "Loss: 0.5159293570870227\n",
      "Loss: 0.5159030115928063\n",
      "Loss: 0.5158780171347569\n",
      "Loss: 0.5158542947489143\n",
      "Loss: 0.5158317706703665\n",
      "Loss: 0.5158103759429297\n",
      "Loss: 0.5157900460625954\n",
      "Loss: 0.5157707206513852\n",
      "Loss: 0.5157523431586412\n",
      "Loss: 0.5157348605871018\n",
      "Loss: 0.5157182232414027\n",
      "Loss: 0.515702384496901\n",
      "Loss: 0.5156873005869403\n",
      "Loss: 0.515672930406874\n",
      "Loss: 0.5156592353333355\n",
      "Loss: 0.5156461790574025\n",
      "Loss: 0.5156337274304363\n",
      "Loss: 0.5156218483214968\n",
      "Loss: 0.5156105114853463\n",
      "Loss: 0.5155996884401473\n",
      "Loss: 0.5155893523540456\n",
      "Loss: 0.5155794779399089\n",
      "Loss: 0.5155700413575555\n",
      "Loss: 0.5155610201228712\n",
      "Loss: 0.5155523930232694\n",
      "Loss: 0.5155441400389925\n",
      "Loss: 0.5155362422698037\n",
      "Loss: 0.5155286818666527\n",
      "Loss: 0.51552144196794\n",
      "Loss: 0.5155145066400324\n",
      "Loss: 0.515507860821711\n",
      "Loss: 0.5155014902722673\n",
      "Loss: 0.5154953815229775\n",
      "Loss: 0.5154895218317102\n",
      "Loss: 0.515483899140447\n",
      "Loss: 0.515478502035506\n",
      "Loss: 0.5154733197102801\n",
      "Loss: 0.5154683419303148\n",
      "Loss: 0.5154635590005633\n",
      "Loss: 0.5154589617346704\n",
      "Loss: 0.5154545414261488\n",
      "Loss: 0.5154502898213158\n",
      "Loss: 0.5154461990938801\n",
      "Loss: 0.5154422618210613\n",
      "Loss: 0.5154384709611484\n",
      "Loss: 0.5154348198323973\n",
      "Loss: 0.5154313020931853\n",
      "Loss: 0.5154279117233382\n",
      "Loss: 0.5154246430065567\n",
      "Loss: 0.515421490513872\n",
      "Loss: 0.5154184490880656\n",
      "Loss: 0.515415513828991\n",
      "Loss: 0.5154126800797455\n",
      "Loss: 0.5154099434136341\n",
      "Loss: 0.51540729962188\n",
      "Loss: 0.5154047447020356\n",
      "Loss: 0.5154022748470495\n",
      "Loss: 0.5153998864349523\n",
      "Loss: 0.5153975760191216\n",
      "Loss: 0.5153953403190932\n",
      "Loss: 0.5153931762118841\n",
      "Loss: 0.5153910807237985\n",
      "Loss: 0.5153890510226881\n",
      "Loss: 0.515387084410638\n",
      "Loss: 0.5153851783170563\n",
      "Loss: 0.5153833302921416\n",
      "Loss: 0.5153815380007062\n",
      "Loss: 0.5153797992163373\n",
      "Loss: 0.5153781118158731\n",
      "Loss: 0.5153764737741783\n",
      "Loss: 0.5153748831591999\n",
      "Loss: 0.5153733381272904\n",
      "Loss: 0.5153718369187787\n",
      "Loss: 0.5153703778537796\n",
      "Loss: 0.5153689593282247\n",
      "Loss: 0.5153675798101037\n",
      "Loss: 0.5153662378359053\n",
      "Loss: 0.5153649320072445\n",
      "Loss: 0.5153636609876681\n",
      "Loss: 0.5153624234996255\n",
      "Loss: 0.5153612183216013\n",
      "Loss: 0.5153600442853926\n",
      "Loss: 0.5153589002735316\n",
      "Loss: 0.5153577852168386\n",
      "Loss: 0.5153566980921032\n",
      "Loss: 0.5153556379198841\n",
      "Loss: 0.5153546037624217\n",
      "Loss: 0.5153535947216569\n",
      "Loss: 0.5153526099373524\n",
      "Loss: 0.5153516485853084\n",
      "Loss: 0.5153507098756687\n",
      "Loss: 0.5153497930513128\n",
      "Loss: 0.5153488973863303\n",
      "Loss: 0.5153480221845682\n",
      "Loss: 0.5153471667782561\n",
      "Loss: 0.5153463305266958\n",
      "Loss: 0.5153455128150184\n",
      "Loss: 0.515344713053003\n",
      "Loss: 0.5153439306739528\n",
      "Loss: 0.5153431651336281\n",
      "Loss: 0.5153424159092309\n",
      "Loss: 0.5153416824984395\n",
      "Loss: 0.5153409644184909\n",
      "Loss: 0.5153402612053066\n",
      "Loss: 0.5153395724126633\n",
      "Loss: 0.5153388976114007\n",
      "Loss: 0.5153382363886709\n",
      "Loss: 0.5153375883472212\n",
      "Loss: 0.5153369531047127\n",
      "Loss: 0.5153363302930721\n",
      "Loss: 0.5153357195578726\n",
      "Loss: 0.5153351205577459\n",
      "Loss: 0.5153345329638218\n",
      "Loss: 0.5153339564591932\n",
      "Loss: 0.515333390738408\n",
      "Loss: 0.5153328355069834\n",
      "Loss: 0.5153322904809439\n",
      "Loss: 0.5153317553863801\n",
      "Loss: 0.5153312299590287\n",
      "Loss: 0.5153307139438714\n",
      "Loss: 0.5153302070947532\n",
      "Loss: 0.5153297091740161\n",
      "Loss: 0.515329219952153\n",
      "Loss: 0.5153287392074742\n",
      "Loss: 0.515328266725791\n",
      "Loss: 0.5153278023001125\n",
      "Loss: 0.5153273457303574\n",
      "Loss: 0.5153268968230772\n",
      "Loss: 0.5153264553911934\n",
      "Loss: 0.5153260212537447\n",
      "Loss: 0.5153255942356473\n",
      "Loss: 0.5153251741674645\n",
      "Loss: 0.515324760885187\n",
      "Loss: 0.5153243542300225\n",
      "Loss: 0.5153239540481955\n",
      "Loss: 0.5153235601907538\n",
      "Loss: 0.5153231725133863\n",
      "Loss: 0.5153227908762458\n",
      "Loss: 0.5153224151437815\n",
      "Loss: 0.5153220451845778\n",
      "Loss: 0.5153216808711995\n",
      "Loss: 0.515321322080045\n",
      "Loss: 0.5153209686912045\n",
      "Loss: 0.5153206205883252\n",
      "Loss: 0.5153202776584801\n",
      "Loss: 0.5153199397920456\n",
      "Loss: 0.515319606882581\n",
      "Loss: 0.5153192788267151\n",
      "Loss: 0.5153189555240361\n",
      "Loss: 0.5153186368769874\n",
      "Loss: 0.5153183227907661\n",
      "Loss: 0.5153180131732271\n",
      "Loss: 0.51531770793479\n",
      "Loss: 0.5153174069883506\n",
      "Loss: 0.5153171102491952\n",
      "Loss: 0.5153168176349187\n",
      "Loss: 0.5153165290653461\n",
      "Loss: 0.5153162444624566\n",
      "Loss: 0.5153159637503117\n",
      "Loss: 0.5153156868549845\n",
      "Loss: 0.5153154137044936\n",
      "Loss: 0.5153151442287383\n",
      "Loss: 0.5153148783594361\n",
      "Loss: 0.5153146160300646\n",
      "Loss: 0.5153143571758028\n",
      "Loss: 0.5153141017334766\n",
      "Loss: 0.515313849641506\n",
      "Loss: 0.5153136008398539\n",
      "Loss: 0.5153133552699771\n",
      "Loss: 0.5153131128747789\n",
      "Loss: 0.5153128735985638\n",
      "Loss: 0.5153126373869935\n",
      "Loss: 0.5153124041870454\n",
      "Loss: 0.5153121739469705\n",
      "Loss: 0.5153119466162558\n",
      "Loss: 0.515311722145586\n",
      "Loss: 0.5153115004868064\n",
      "Loss: 0.5153112815928892\n",
      "Loss: 0.5153110654178983\n",
      "Loss: 0.5153108519169579\n",
      "Loss: 0.5153106410462202\n",
      "Loss: 0.5153104327628351\n",
      "Loss: 0.5153102270249216\n",
      "Loss: 0.5153100237915388\n",
      "Loss: 0.5153098230226589\n",
      "Loss: 0.5153096246791408\n",
      "Loss: 0.5153094287227048\n",
      "Loss: 0.5153092351159078\n",
      "Loss: 0.5153090438221197\n",
      "Loss: 0.5153088548055008\n",
      "Loss: 0.5153086680309786\n",
      "Loss: 0.5153084834642278\n",
      "Loss: 0.515308301071648\n",
      "Loss: 0.5153081208203457\n",
      "Loss: 0.5153079426781125\n",
      "Loss: 0.5153077666134089\n",
      "Loss: 0.5153075925953441\n",
      "Loss: 0.5153074205936595\n",
      "Loss: 0.515307250578712\n",
      "Loss: 0.5153070825214567\n",
      "Loss: 0.5153069163934321\n",
      "Loss: 0.5153067521667432\n",
      "Loss: 0.5153065898140482\n",
      "Loss: 0.5153064293085434\n",
      "Loss: 0.5153062706239493\n",
      "Loss: 0.5153061137344966\n",
      "Loss: 0.5153059586149141\n",
      "Loss: 0.5153058052404151\n",
      "Loss: 0.5153056535866857\n",
      "Loss: 0.515305503629872\n",
      "Loss: 0.5153053553465702\n",
      "Loss: 0.5153052087138134\n",
      "Loss: 0.5153050637090618\n",
      "Loss: 0.5153049203101925\n",
      "Loss: 0.5153047784954885\n",
      "Loss: 0.5153046382436293\n",
      "Loss: 0.5153044995336804\n",
      "Loss: 0.5153043623450854\n",
      "Loss: 0.5153042266576556\n",
      "Loss: 0.5153040924515623\n",
      "Loss: 0.515303959707327\n",
      "Loss: 0.5153038284058145\n",
      "Loss: 0.5153036985282236\n",
      "Loss: 0.5153035700560802\n",
      "Loss: 0.5153034429712291\n",
      "Loss: 0.515303317255827\n",
      "Loss: 0.5153031928923353\n",
      "Loss: 0.5153030698635125\n",
      "Loss: 0.5153029481524088\n",
      "Loss: 0.5153028277423578\n",
      "Loss: 0.5153027086169715\n",
      "Loss: 0.5153025907601333\n",
      "Loss: 0.5153024741559924\n",
      "Loss: 0.5153023587889577\n",
      "Loss: 0.5153022446436917\n",
      "Loss: 0.5153021317051057\n",
      "Loss: 0.5153020199583545\n",
      "Loss: 0.5153019093888295\n",
      "Loss: 0.5153017999821559\n",
      "Loss: 0.5153016917241855\n",
      "Loss: 0.5153015846009938\n",
      "Loss: 0.5153014785988741\n",
      "Loss: 0.5153013737043327\n",
      "Loss: 0.5153012699040859\n",
      "Loss: 0.5153011671850535\n",
      "Loss: 0.5153010655343567\n",
      "Loss: 0.5153009649393122\n",
      "Loss: 0.5153008653874297\n",
      "Loss: 0.5153007668664065\n",
      "Loss: 0.5153006693641248\n",
      "Loss: 0.5153005728686477\n",
      "Loss: 0.5153004773682149\n",
      "Loss: 0.5153003828512406\n",
      "Loss: 0.5153002893063082\n",
      "Loss: 0.5153001967221689\n",
      "Loss: 0.5153001050877364\n",
      "Loss: 0.5153000143920855\n",
      "Loss: 0.5152999246244481\n",
      "Loss: 0.5152998357742101\n",
      "Loss: 0.5152997478309087\n",
      "Loss: 0.5152996607842296\n",
      "Loss: 0.5152995746240039\n",
      "Loss: 0.5152994893402056\n",
      "Loss: 0.5152994049229487\n",
      "Loss: 0.5152993213624847\n",
      "Loss: 0.5152992386491997\n",
      "Loss: 0.5152991567736129\n",
      "Loss: 0.515299075726373\n",
      "Loss: 0.5152989954982566\n",
      "Loss: 0.5152989160801656\n",
      "Loss: 0.5152988374631244\n",
      "Loss: 0.5152987596382789\n",
      "Loss: 0.5152986825968935\n",
      "Loss: 0.5152986063303489\n",
      "Loss: 0.5152985308301404\n",
      "Loss: 0.5152984560878761\n",
      "Loss: 0.5152983820952739\n",
      "Loss: 0.5152983088441611\n",
      "Loss: 0.5152982363264712\n",
      "Loss: 0.5152981645342427\n",
      "Loss: 0.5152980934596171\n",
      "Loss: 0.5152980230948373\n",
      "Loss: 0.5152979534322458\n",
      "Loss: 0.5152978844642832\n",
      "Loss: 0.5152978161834858\n",
      "Loss: 0.5152977485824852\n",
      "Loss: 0.515297681654006\n",
      "Loss: 0.515297615390864\n",
      "Loss: 0.5152975497859654\n",
      "Loss: 0.515297484832305\n",
      "Loss: 0.5152974205229643\n",
      "Loss: 0.5152973568511114\n",
      "Loss: 0.5152972938099981\n",
      "Loss: 0.5152972313929594\n",
      "Loss: 0.515297169593412\n",
      "Loss: 0.5152971084048532\n",
      "Loss: 0.5152970478208593\n",
      "Loss: 0.5152969878350844\n",
      "Loss: 0.5152969284412594\n",
      "Loss: 0.515296869633191\n",
      "Loss: 0.5152968114047597\n",
      "Loss: 0.5152967537499196\n",
      "Loss: 0.5152966966626968\n",
      "Loss: 0.5152966401371883\n",
      "Loss: 0.5152965841675613\n",
      "Loss: 0.5152965287480515\n",
      "Loss: 0.5152964738729628\n",
      "Loss: 0.5152964195366658\n",
      "Loss: 0.5152963657335968\n",
      "Loss: 0.515296312458257\n",
      "Loss: 0.515296259705212\n",
      "Loss: 0.5152962074690897\n",
      "Loss: 0.5152961557445807\n",
      "Loss: 0.5152961045264364\n",
      "Loss: 0.5152960538094683\n",
      "Loss: 0.5152960035885481\n",
      "Loss: 0.5152959538586055\n",
      "Loss: 0.5152959046146283\n",
      "Loss: 0.5152958558516606\n",
      "Loss: 0.5152958075648038\n",
      "Loss: 0.5152957597492134\n",
      "Loss: 0.5152957124001003\n",
      "Loss: 0.5152956655127293\n",
      "Loss: 0.5152956190824176\n",
      "Loss: 0.5152955731045357\n",
      "Loss: 0.5152955275745049\n",
      "Loss: 0.5152954824877982\n",
      "Loss: 0.5152954378399381\n",
      "Loss: 0.5152953936264976\n",
      "Loss: 0.5152953498430975\n",
      "Loss: 0.5152953064854079\n",
      "Loss: 0.5152952635491462\n",
      "Loss: 0.5152952210300764\n",
      "Loss: 0.5152951789240094\n",
      "Loss: 0.5152951372268014\n",
      "Loss: 0.5152950959343545\n",
      "Loss: 0.5152950550426146\n",
      "Loss: 0.5152950145475718\n",
      "Loss: 0.51529497444526\n",
      "Loss: 0.5152949347317556\n",
      "Loss: 0.5152948954031775\n",
      "Loss: 0.5152948564556865\n",
      "Loss: 0.5152948178854841\n",
      "Loss: 0.5152947796888132\n",
      "Loss: 0.5152947418619567\n",
      "Loss: 0.515294704401237\n",
      "Loss: 0.515294667303016\n",
      "Loss: 0.5152946305636941\n",
      "Loss: 0.51529459417971\n",
      "Loss: 0.5152945581475403\n",
      "Loss: 0.5152945224636989\n",
      "Loss: 0.5152944871247365\n",
      "Loss: 0.5152944521272399\n",
      "Loss: 0.5152944174678322\n",
      "Loss: 0.5152943831431722\n",
      "Loss: 0.5152943491499534\n",
      "Loss: 0.5152943154849039\n",
      "Loss: 0.5152942821447863\n",
      "Loss: 0.515294249126397\n",
      "Loss: 0.5152942164265658\n",
      "Loss: 0.5152941840421554\n",
      "Loss: 0.5152941519700616\n",
      "Loss: 0.5152941202072115\n",
      "Loss: 0.5152940887505651\n",
      "Loss: 0.5152940575971136\n",
      "Loss: 0.5152940267438786\n",
      "Loss: 0.5152939961879135\n",
      "Loss: 0.5152939659263014\n",
      "Loss: 0.515293935956156\n",
      "Loss: 0.51529390627462\n",
      "Loss: 0.5152938768788663\n",
      "Loss: 0.515293847766096\n",
      "Loss: 0.5152938189335394\n",
      "Loss: 0.515293790378455\n",
      "Loss: 0.5152937620981294\n",
      "Loss: 0.5152937340898768\n",
      "Loss: 0.5152937063510388\n",
      "Loss: 0.5152936788789843\n",
      "Loss: 0.5152936516711086\n",
      "Loss: 0.5152936247248339\n",
      "Loss: 0.5152935980376084\n",
      "Loss: 0.515293571606906\n",
      "Loss: 0.5152935454302265\n",
      "Loss: 0.5152935195050948\n",
      "Loss: 0.5152934938290612\n",
      "Loss: 0.5152934683997\n",
      "Loss: 0.5152934432146107\n",
      "Loss: 0.5152934182714168\n",
      "Loss: 0.5152933935677657\n",
      "Loss: 0.5152933691013283\n",
      "Loss: 0.5152933448697992\n",
      "Loss: 0.515293320870896\n",
      "Loss: 0.5152932971023594\n",
      "Loss: 0.5152932735619523\n",
      "Loss: 0.5152932502474609\n",
      "Loss: 0.5152932271566923\n",
      "Loss: 0.5152932042874768\n",
      "Loss: 0.5152931816376655\n",
      "Loss: 0.5152931592051313\n",
      "Loss: 0.5152931369877684\n",
      "Loss: 0.5152931149834918\n",
      "Loss: 0.5152930931902373\n",
      "Loss: 0.5152930716059616\n",
      "Loss: 0.5152930502286411\n",
      "Loss: 0.5152930290562728\n",
      "Loss: 0.5152930080868736\n",
      "Loss: 0.5152929873184797\n",
      "Loss: 0.5152929667491472\n",
      "Loss: 0.5152929463769511\n",
      "Loss: 0.5152929261999858\n",
      "Loss: 0.5152929062163644\n",
      "Loss: 0.5152928864242188\n",
      "Loss: 0.515292866821699\n",
      "Loss: 0.5152928474069738\n",
      "Loss: 0.5152928281782296\n",
      "Loss: 0.515292809133671\n",
      "Loss: 0.5152927902715204\n",
      "Loss: 0.5152927715900175\n",
      "Loss: 0.5152927530874192\n",
      "Loss: 0.515292734762\n",
      "Loss: 0.5152927166120509\n",
      "Loss: 0.5152926986358801\n",
      "Loss: 0.5152926808318122\n",
      "Loss: 0.5152926631981886\n",
      "Loss: 0.5152926457333663\n",
      "Loss: 0.5152926284357192\n",
      "Loss: 0.5152926113036367\n",
      "Loss: 0.515292594335524\n",
      "Loss: 0.5152925775298022\n",
      "Loss: 0.5152925608849075\n",
      "Loss: 0.5152925443992917\n",
      "Loss: 0.5152925280714218\n",
      "Loss: 0.5152925118997794\n",
      "Loss: 0.5152924958828614\n",
      "Loss: 0.515292480019179\n",
      "Loss: 0.5152924643072585\n",
      "Loss: 0.5152924487456397\n",
      "Loss: 0.5152924333328777\n",
      "Loss: 0.5152924180675409\n",
      "Loss: 0.5152924029482118\n",
      "Loss: 0.5152923879734873\n",
      "Loss: 0.5152923731419772\n",
      "Loss: 0.5152923584523053\n",
      "Loss: 0.5152923439031087\n",
      "Loss: 0.5152923294930377\n",
      "Loss: 0.515292315220756\n",
      "Loss: 0.51529230108494\n",
      "Loss: 0.5152922870842788\n",
      "Loss: 0.5152922732174746\n",
      "Loss: 0.5152922594832424\n",
      "Loss: 0.5152922458803092\n",
      "Loss: 0.5152922324074147\n",
      "Loss: 0.5152922190633107\n",
      "Loss: 0.5152922058467609\n",
      "Loss: 0.5152921927565415\n",
      "Loss: 0.51529217979144\n",
      "Loss: 0.5152921669502563\n",
      "Loss: 0.5152921542318013\n",
      "Loss: 0.5152921416348979\n",
      "Loss: 0.5152921291583801\n",
      "Loss: 0.5152921168010933\n",
      "Loss: 0.5152921045618942\n",
      "Loss: 0.5152920924396505\n",
      "Loss: 0.5152920804332406\n",
      "Loss: 0.5152920685415543\n",
      "Loss: 0.5152920567634914\n",
      "Loss: 0.5152920450979631\n",
      "Loss: 0.5152920335438907\n",
      "Loss: 0.515292022100206\n",
      "Loss: 0.5152920107658511\n",
      "Loss: 0.5152919995397784\n",
      "Loss: 0.5152919884209504\n",
      "Loss: 0.5152919774083395\n",
      "Loss: 0.5152919665009282\n",
      "Loss: 0.5152919556977089\n",
      "Loss: 0.5152919449976834\n",
      "Loss: 0.5152919343998632\n",
      "Loss: 0.5152919239032696\n",
      "Loss: 0.5152919135069333\n",
      "Loss: 0.5152919032098939\n",
      "Loss: 0.515291893011201\n",
      "Loss: 0.5152918829099127\n",
      "Loss: 0.5152918729050965\n",
      "Loss: 0.5152918629958287\n",
      "Loss: 0.515291853181195\n",
      "Loss: 0.5152918434602891\n",
      "Loss: 0.5152918338322141\n",
      "Loss: 0.5152918242960814\n",
      "Loss: 0.5152918148510112\n",
      "Loss: 0.5152918054961318\n",
      "Loss: 0.5152917962305805\n",
      "Loss: 0.5152917870535022\n",
      "Loss: 0.5152917779640503\n",
      "Loss: 0.5152917689613867\n",
      "Loss: 0.5152917600446809\n",
      "Loss: 0.5152917512131104\n",
      "Loss: 0.5152917424658611\n",
      "Loss: 0.515291733802126\n",
      "Loss: 0.5152917252211066\n",
      "Loss: 0.5152917167220115\n",
      "Loss: 0.5152917083040571\n",
      "Loss: 0.5152916999664676\n",
      "Loss: 0.5152916917084742\n",
      "Loss: 0.5152916835293159\n",
      "Loss: 0.5152916754282387\n",
      "Loss: 0.5152916674044957\n",
      "Loss: 0.5152916594573479\n",
      "Loss: 0.5152916515860628\n",
      "Loss: 0.5152916437899148\n",
      "Loss: 0.5152916360681857\n",
      "Loss: 0.5152916284201642\n",
      "Loss: 0.5152916208451455\n",
      "Loss: 0.5152916133424316\n",
      "Loss: 0.5152916059113314\n",
      "Loss: 0.5152915985511604\n",
      "Loss: 0.5152915912612406\n",
      "Loss: 0.5152915840409006\n",
      "Loss: 0.5152915768894751\n",
      "Loss: 0.5152915698063056\n",
      "Loss: 0.5152915627907401\n",
      "Loss: 0.515291555842132\n",
      "Loss: 0.5152915489598415\n",
      "Loss: 0.5152915421432351\n",
      "Loss: 0.515291535391685\n",
      "Loss: 0.5152915287045694\n",
      "Loss: 0.5152915220812728\n",
      "Loss: 0.5152915155211855\n",
      "Loss: 0.5152915090237032\n",
      "Loss: 0.5152915025882281\n",
      "Loss: 0.5152914962141674\n",
      "Loss: 0.5152914899009347\n",
      "Loss: 0.5152914836479485\n",
      "Loss: 0.5152914774546338\n",
      "Loss: 0.5152914713204199\n",
      "Loss: 0.5152914652447427\n",
      "Loss: 0.5152914592270427\n",
      "Loss: 0.5152914532667662\n",
      "Loss: 0.5152914473633647\n",
      "Loss: 0.5152914415162951\n",
      "Loss: 0.515291435725019\n",
      "Loss: 0.5152914299890037\n",
      "Loss: 0.5152914243077213\n",
      "Loss: 0.5152914186806491\n",
      "Loss: 0.5152914131072693\n",
      "Loss: 0.5152914075870692\n",
      "Loss: 0.5152914021195408\n",
      "Loss: 0.5152913967041811\n",
      "Loss: 0.5152913913404921\n",
      "Loss: 0.5152913860279801\n",
      "Loss: 0.5152913807661563\n",
      "Loss: 0.515291375554537\n",
      "Loss: 0.5152913703926424\n",
      "Loss: 0.5152913652799982\n",
      "Loss: 0.5152913602161335\n",
      "Loss: 0.515291355200583\n",
      "Loss: 0.5152913502328852\n",
      "Loss: 0.5152913453125831\n",
      "Loss: 0.5152913404392244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5152913356123607\n",
      "Loss: 0.5152913308315481\n",
      "Loss: 0.515291326096347\n",
      "Loss: 0.5152913214063218\n",
      "Loss: 0.5152913167610413\n",
      "Loss: 0.5152913121600784\n",
      "Loss: 0.5152913076030098\n",
      "Loss: 0.5152913030894166\n",
      "Loss: 0.5152912986188837\n",
      "Loss: 0.5152912941910001\n",
      "Loss: 0.5152912898053584\n",
      "Loss: 0.5152912854615556\n",
      "Loss: 0.5152912811591922\n",
      "Loss: 0.5152912768978729\n",
      "Loss: 0.5152912726772055\n",
      "Loss: 0.5152912684968021\n",
      "Loss: 0.5152912643562784\n",
      "Loss: 0.5152912602552538\n",
      "Loss: 0.5152912561933511\n",
      "Loss: 0.5152912521701971\n",
      "Loss: 0.5152912481854217\n",
      "Loss: 0.5152912442386587\n",
      "Loss: 0.5152912403295453\n",
      "Loss: 0.5152912364577221\n",
      "Loss: 0.5152912326228334\n",
      "Loss: 0.5152912288245263\n",
      "Loss: 0.515291225062452\n",
      "Loss: 0.5152912213362643\n",
      "Loss: 0.515291217645621\n",
      "Loss: 0.515291213990183\n",
      "Loss: 0.515291210369614\n",
      "Loss: 0.5152912067835814\n",
      "Loss: 0.5152912032317554\n",
      "Loss: 0.5152911997138098\n",
      "Loss: 0.5152911962294212\n",
      "Loss: 0.5152911927782692\n",
      "Loss: 0.5152911893600367\n",
      "Loss: 0.5152911859744096\n",
      "Loss: 0.5152911826210768\n",
      "Loss: 0.5152911792997299\n",
      "Loss: 0.5152911760100638\n",
      "Loss: 0.5152911727517763\n",
      "Loss: 0.5152911695245678\n",
      "Loss: 0.5152911663281419\n",
      "Loss: 0.5152911631622045\n",
      "Loss: 0.5152911600264649\n",
      "Loss: 0.5152911569206352\n",
      "Loss: 0.5152911538444295\n",
      "Loss: 0.5152911507975654\n",
      "Loss: 0.5152911477797629\n",
      "Loss: 0.5152911447907447\n",
      "Loss: 0.5152911418302362\n",
      "Loss: 0.5152911388979652\n",
      "Loss: 0.5152911359936623\n",
      "Loss: 0.5152911331170608\n",
      "Loss: 0.5152911302678963\n",
      "Loss: 0.5152911274459069\n",
      "Loss: 0.5152911246508335\n",
      "Loss: 0.515291121882419\n",
      "Loss: 0.5152911191404094\n",
      "Loss: 0.5152911164245525\n",
      "Loss: 0.5152911137345989\n",
      "Loss: 0.5152911110703015\n",
      "Loss: 0.5152911084314153\n",
      "Loss: 0.5152911058176982\n",
      "Loss: 0.5152911032289097\n",
      "Loss: 0.5152911006648121\n",
      "Loss: 0.5152910981251698\n",
      "Loss: 0.5152910956097497\n",
      "Loss: 0.5152910931183204\n",
      "Loss: 0.5152910906506534\n",
      "Loss: 0.5152910882065215\n",
      "Loss: 0.5152910857857004\n",
      "Loss: 0.5152910833879678\n",
      "Loss: 0.5152910810131034\n",
      "Loss: 0.5152910786608889\n",
      "Loss: 0.5152910763311083\n",
      "Loss: 0.5152910740235476\n",
      "Loss: 0.5152910717379947\n",
      "Loss: 0.51529106947424\n",
      "Loss: 0.515291067232075\n",
      "Loss: 0.5152910650112941\n",
      "Loss: 0.5152910628116932\n",
      "Loss: 0.5152910606330705\n",
      "Loss: 0.5152910584752253\n",
      "Loss: 0.5152910563379599\n",
      "Loss: 0.5152910542210778\n",
      "Loss: 0.5152910521243845\n",
      "Loss: 0.5152910500476876\n",
      "Loss: 0.5152910479907961\n",
      "Loss: 0.5152910459535212\n",
      "Loss: 0.5152910439356758\n",
      "Loss: 0.5152910419370743\n",
      "Loss: 0.5152910399575334\n",
      "Loss: 0.5152910379968713\n",
      "Loss: 0.5152910360549078\n",
      "Loss: 0.5152910341314645\n",
      "Loss: 0.5152910322263649\n",
      "Loss: 0.5152910303394338\n",
      "Loss: 0.5152910284704979\n",
      "Loss: 0.5152910266193856\n",
      "Loss: 0.5152910247859271\n",
      "Loss: 0.5152910229699538\n",
      "Loss: 0.5152910211712988\n",
      "Loss: 0.515291019389797\n",
      "Loss: 0.515291017625285\n",
      "Loss: 0.5152910158776004\n",
      "Loss: 0.5152910141465828\n",
      "Loss: 0.5152910124320732\n",
      "Loss: 0.5152910107339144\n",
      "Loss: 0.5152910090519501\n",
      "Loss: 0.5152910073860258\n",
      "Loss: 0.515291005735989\n",
      "Loss: 0.5152910041016875\n",
      "Loss: 0.5152910024829717\n",
      "Loss: 0.5152910008796927\n",
      "Loss: 0.5152909992917033\n",
      "Loss: 0.5152909977188576\n",
      "Loss: 0.5152909961610113\n",
      "Loss: 0.5152909946180212\n",
      "Loss: 0.5152909930897458\n",
      "Loss: 0.5152909915760444\n",
      "Loss: 0.5152909900767784\n",
      "Loss: 0.5152909885918098\n",
      "Loss: 0.5152909871210023\n",
      "Loss: 0.5152909856642209\n",
      "Loss: 0.515290984221332\n",
      "Loss: 0.5152909827922026\n",
      "Loss: 0.5152909813767019\n",
      "Loss: 0.5152909799746996\n",
      "Loss: 0.5152909785860673\n",
      "Loss: 0.5152909772106771\n",
      "Loss: 0.515290975848403\n",
      "Loss: 0.5152909744991198\n",
      "Loss: 0.5152909731627034\n",
      "Loss: 0.5152909718390313\n",
      "Loss: 0.5152909705279821\n",
      "Loss: 0.5152909692294351\n",
      "Loss: 0.5152909679432711\n",
      "Loss: 0.5152909666693721\n",
      "Loss: 0.5152909654076212\n",
      "Loss: 0.5152909641579022\n",
      "Loss: 0.5152909629201008\n",
      "Loss: 0.5152909616941029\n",
      "Loss: 0.5152909604797963\n",
      "Loss: 0.5152909592770691\n",
      "Loss: 0.5152909580858113\n",
      "Loss: 0.5152909569059132\n",
      "Loss: 0.5152909557372666\n",
      "Loss: 0.515290954579764\n",
      "Loss: 0.5152909534332992\n",
      "Loss: 0.5152909522977672\n",
      "Loss: 0.5152909511730634\n",
      "Loss: 0.5152909500590848\n",
      "Loss: 0.5152909489557287\n",
      "Loss: 0.5152909478628941\n",
      "Loss: 0.5152909467804807\n",
      "Loss: 0.515290945708389\n",
      "Loss: 0.5152909446465205\n",
      "Loss: 0.5152909435947779\n",
      "Loss: 0.5152909425530643\n",
      "Loss: 0.5152909415212844\n",
      "Loss: 0.5152909404993432\n",
      "Loss: 0.515290939487147\n",
      "Loss: 0.515290938484603\n",
      "Loss: 0.5152909374916186\n",
      "Loss: 0.5152909365081033\n",
      "Loss: 0.5152909355339664\n",
      "Loss: 0.5152909345691186\n",
      "Loss: 0.5152909336134713\n",
      "Loss: 0.5152909326669367\n",
      "Loss: 0.515290931729428\n",
      "Loss: 0.5152909308008589\n",
      "Loss: 0.5152909298811443\n",
      "Loss: 0.5152909289701999\n",
      "Loss: 0.5152909280679417\n",
      "Loss: 0.5152909271742873\n",
      "Loss: 0.5152909262891542\n",
      "Loss: 0.5152909254124616\n",
      "Loss: 0.5152909245441285\n",
      "Loss: 0.5152909236840755\n",
      "Loss: 0.5152909228322236\n",
      "Loss: 0.5152909219884945\n",
      "Loss: 0.5152909211528108\n",
      "Loss: 0.5152909203250957\n",
      "Loss: 0.5152909195052734\n",
      "Loss: 0.5152909186932685\n",
      "Loss: 0.5152909178890064\n",
      "Loss: 0.5152909170924133\n",
      "Loss: 0.5152909163034161\n",
      "Loss: 0.5152909155219423\n",
      "Loss: 0.5152909147479201\n",
      "Loss: 0.5152909139812787\n",
      "Loss: 0.5152909132219474\n",
      "Loss: 0.5152909124698568\n",
      "Loss: 0.5152909117249374\n",
      "Loss: 0.5152909109871213\n",
      "Loss: 0.5152909102563404\n",
      "Loss: 0.5152909095325279\n",
      "Loss: 0.5152909088156171\n",
      "Loss: 0.5152909081055422\n",
      "Loss: 0.5152909074022383\n",
      "Loss: 0.5152909067056406\n",
      "Loss: 0.5152909060156851\n",
      "Loss: 0.5152909053323085\n",
      "Loss: 0.5152909046554481\n",
      "Loss: 0.5152909039850418\n",
      "Loss: 0.515290903321028\n",
      "Loss: 0.5152909026633458\n",
      "Loss: 0.5152909020119346\n",
      "Loss: 0.5152909013667348\n",
      "Loss: 0.5152909007276872\n",
      "Loss: 0.5152909000947331\n",
      "Loss: 0.5152908994678143\n",
      "Loss: 0.5152908988468732\n",
      "Loss: 0.515290898231853\n",
      "Loss: 0.5152908976226971\n",
      "Loss: 0.5152908970193496\n",
      "Loss: 0.5152908964217552\n",
      "Loss: 0.5152908958298589\n",
      "Loss: 0.5152908952436063\n",
      "Loss: 0.5152908946629439\n",
      "Loss: 0.515290894087818\n",
      "Loss: 0.5152908935181761\n",
      "Loss: 0.5152908929539657\n",
      "Loss: 0.5152908923951354\n",
      "Loss: 0.5152908918416333\n",
      "Loss: 0.515290891293409\n",
      "Loss: 0.515290890750412\n",
      "Loss: 0.5152908902125927\n",
      "Loss: 0.5152908896799013\n",
      "Loss: 0.5152908891522893\n",
      "Loss: 0.515290888629708\n",
      "Loss: 0.5152908881121095\n",
      "Loss: 0.5152908875994465\n",
      "Loss: 0.5152908870916717\n",
      "Loss: 0.5152908865887385\n",
      "Loss: 0.5152908860906007\n",
      "Loss: 0.5152908855972127\n",
      "Loss: 0.515290885108529\n",
      "Loss: 0.5152908846245052\n",
      "Loss: 0.5152908841450964\n",
      "Loss: 0.5152908836702588\n",
      "Loss: 0.5152908831999486\n",
      "Loss: 0.5152908827341229\n",
      "Loss: 0.5152908822727389\n",
      "Loss: 0.515290881815754\n",
      "Loss: 0.5152908813631266\n",
      "Loss: 0.5152908809148149\n",
      "Loss: 0.5152908804707778\n",
      "Loss: 0.5152908800309746\n",
      "Loss: 0.5152908795953646\n",
      "Loss: 0.5152908791639084\n",
      "Loss: 0.515290878736566\n",
      "Loss: 0.5152908783132982\n",
      "Loss: 0.5152908778940664\n",
      "Loss: 0.5152908774788317\n",
      "Loss: 0.5152908770675563\n",
      "Loss: 0.5152908766602023\n",
      "Loss: 0.5152908762567323\n",
      "Loss: 0.5152908758571095\n",
      "Loss: 0.5152908754612968\n",
      "Loss: 0.5152908750692583\n",
      "Loss: 0.5152908746809578\n",
      "Loss: 0.5152908742963597\n",
      "Loss: 0.5152908739154285\n",
      "Loss: 0.5152908735381294\n",
      "Loss: 0.5152908731644278\n",
      "Loss: 0.5152908727942894\n",
      "Loss: 0.5152908724276803\n",
      "Loss: 0.5152908720645666\n",
      "Loss: 0.5152908717049152\n",
      "Loss: 0.5152908713486929\n",
      "Loss: 0.5152908709958671\n",
      "Loss: 0.5152908706464054\n",
      "Loss: 0.5152908703002758\n",
      "Loss: 0.5152908699574463\n",
      "Loss: 0.5152908696178858\n",
      "Loss: 0.5152908692815628\n",
      "Loss: 0.5152908689484466\n",
      "Loss: 0.5152908686185064\n",
      "Loss: 0.5152908682917121\n",
      "Loss: 0.5152908679680338\n",
      "Loss: 0.5152908676474416\n",
      "Loss: 0.5152908673299063\n",
      "Loss: 0.5152908670153984\n",
      "Loss: 0.5152908667038892\n",
      "Loss: 0.5152908663953504\n",
      "Loss: 0.5152908660897532\n",
      "Loss: 0.5152908657870697\n",
      "Loss: 0.5152908654872723\n",
      "Loss: 0.5152908651903334\n",
      "Loss: 0.5152908648962256\n",
      "Loss: 0.5152908646049221\n",
      "Loss: 0.515290864316396\n",
      "Loss: 0.5152908640306209\n",
      "Loss: 0.5152908637475705\n",
      "Loss: 0.515290863467219\n",
      "Loss: 0.5152908631895404\n",
      "Loss: 0.5152908629145094\n",
      "Loss: 0.5152908626421008\n",
      "Loss: 0.5152908623722894\n",
      "Loss: 0.5152908621050505\n",
      "Loss: 0.5152908618403597\n",
      "Loss: 0.5152908615781926\n",
      "Loss: 0.5152908613185251\n",
      "Loss: 0.5152908610613334\n",
      "Loss: 0.515290860806594\n",
      "Loss: 0.5152908605542833\n",
      "Loss: 0.5152908603043783\n",
      "Loss: 0.5152908600568562\n",
      "Loss: 0.5152908598116938\n",
      "Loss: 0.5152908595688692\n",
      "Loss: 0.5152908593283596\n",
      "Loss: 0.5152908590901432\n",
      "Loss: 0.5152908588541981\n",
      "Loss: 0.5152908586205026\n",
      "Loss: 0.5152908583890353\n",
      "Loss: 0.5152908581597749\n",
      "Loss: 0.5152908579327004\n",
      "Loss: 0.5152908577077909\n",
      "Loss: 0.5152908574850259\n",
      "Loss: 0.5152908572643847\n",
      "Loss: 0.5152908570458472\n",
      "Loss: 0.5152908568293935\n",
      "Loss: 0.5152908566150034\n",
      "Loss: 0.5152908564026574\n",
      "Loss: 0.5152908561923362\n",
      "Loss: 0.5152908559840201\n",
      "Loss: 0.5152908557776901\n",
      "Loss: 0.5152908555733275\n",
      "Loss: 0.5152908553709133\n",
      "Loss: 0.515290855170429\n",
      "Loss: 0.5152908549718563\n",
      "Loss: 0.5152908547751768\n",
      "Loss: 0.5152908545803725\n",
      "Loss: 0.5152908543874256\n",
      "Loss: 0.5152908541963183\n",
      "Loss: 0.5152908540070331\n",
      "Loss: 0.5152908538195526\n",
      "Loss: 0.5152908536338596\n",
      "Loss: 0.5152908534499371\n",
      "Loss: 0.5152908532677681\n",
      "Loss: 0.515290853087336\n",
      "Loss: 0.5152908529086243\n",
      "Loss: 0.5152908527316166\n",
      "Loss: 0.5152908525562963\n",
      "Loss: 0.5152908523826475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5152908522106546\n",
      "Loss: 0.5152908520403015\n",
      "Loss: 0.5152908518715724\n",
      "Loss: 0.5152908517044522\n",
      "Loss: 0.5152908515389254\n",
      "Loss: 0.5152908513749767\n",
      "Loss: 0.5152908512125912\n",
      "Loss: 0.5152908510517539\n",
      "Loss: 0.51529085089245\n",
      "Loss: 0.515290850734665\n",
      "Loss: 0.5152908505783844\n",
      "Loss: 0.5152908504235938\n",
      "Loss: 0.515290850270279\n",
      "Loss: 0.515290850118426\n",
      "Loss: 0.5152908499680208\n",
      "Loss: 0.5152908498190496\n",
      "Loss: 0.5152908496714987\n",
      "Loss: 0.5152908495253545\n",
      "Loss: 0.5152908493806039\n",
      "Loss: 0.5152908492372332\n",
      "Loss: 0.5152908490952295\n",
      "Loss: 0.5152908489545797\n",
      "Loss: 0.515290848815271\n",
      "Loss: 0.5152908486772904\n",
      "Loss: 0.5152908485406252\n",
      "Loss: 0.5152908484052633\n",
      "Loss: 0.5152908482711918\n",
      "Loss: 0.5152908481383985\n",
      "Loss: 0.5152908480068714\n",
      "Loss: 0.5152908478765982\n",
      "Loss: 0.5152908477475672\n"
     ]
    }
   ],
   "source": [
    "w, b = gradient_descent(x_train, y_train, w, b, 0.5, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4594a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "accu = predict(x_test, y_test, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de722105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 75.0%.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The accuracy is {accu*100}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06d5ef9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "40/40 [==============================] - 1s 9ms/step - loss: 0.8860 - accuracy: 0.4227 - val_loss: 0.8965 - val_accuracy: 0.4209\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.8488 - accuracy: 0.4473 - val_loss: 0.8593 - val_accuracy: 0.4462\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.8154 - accuracy: 0.4639 - val_loss: 0.8271 - val_accuracy: 0.4715\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7860 - accuracy: 0.4901 - val_loss: 0.7977 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7594 - accuracy: 0.5139 - val_loss: 0.7715 - val_accuracy: 0.5158\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.5313 - val_loss: 0.7479 - val_accuracy: 0.5316\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7144 - accuracy: 0.5551 - val_loss: 0.7276 - val_accuracy: 0.5696\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6956 - accuracy: 0.5797 - val_loss: 0.7098 - val_accuracy: 0.5949\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.6003 - val_loss: 0.6931 - val_accuracy: 0.6076\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6640 - accuracy: 0.6138 - val_loss: 0.6785 - val_accuracy: 0.6139\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6249 - val_loss: 0.6660 - val_accuracy: 0.6076\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.6376 - val_loss: 0.6541 - val_accuracy: 0.6171\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6282 - accuracy: 0.6527 - val_loss: 0.6445 - val_accuracy: 0.6361\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6186 - accuracy: 0.6630 - val_loss: 0.6350 - val_accuracy: 0.6582\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.6646 - val_loss: 0.6271 - val_accuracy: 0.6519\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6026 - accuracy: 0.6717 - val_loss: 0.6199 - val_accuracy: 0.6551\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.6796 - val_loss: 0.6131 - val_accuracy: 0.6551\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5895 - accuracy: 0.6915 - val_loss: 0.6067 - val_accuracy: 0.6646\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5838 - accuracy: 0.6939 - val_loss: 0.6020 - val_accuracy: 0.6741\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.6963 - val_loss: 0.5968 - val_accuracy: 0.6835\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5737 - accuracy: 0.6979 - val_loss: 0.5923 - val_accuracy: 0.6772\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5693 - accuracy: 0.6994 - val_loss: 0.5882 - val_accuracy: 0.6899\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.7002 - val_loss: 0.5847 - val_accuracy: 0.6930\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7050 - val_loss: 0.5810 - val_accuracy: 0.6962\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5584 - accuracy: 0.7058 - val_loss: 0.5778 - val_accuracy: 0.6994\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7090 - val_loss: 0.5750 - val_accuracy: 0.6994\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5524 - accuracy: 0.7098 - val_loss: 0.5725 - val_accuracy: 0.6994\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7153 - val_loss: 0.5700 - val_accuracy: 0.7089\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.7161 - val_loss: 0.5678 - val_accuracy: 0.7184\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.7177 - val_loss: 0.5659 - val_accuracy: 0.7152\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.7224 - val_loss: 0.5639 - val_accuracy: 0.7184\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7240 - val_loss: 0.5621 - val_accuracy: 0.7247\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5395 - accuracy: 0.7232 - val_loss: 0.5606 - val_accuracy: 0.7247\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7256 - val_loss: 0.5593 - val_accuracy: 0.7278\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7264 - val_loss: 0.5577 - val_accuracy: 0.7310\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7280 - val_loss: 0.5566 - val_accuracy: 0.7310\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7256 - val_loss: 0.5553 - val_accuracy: 0.7278\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7280 - val_loss: 0.5540 - val_accuracy: 0.7247\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7256 - val_loss: 0.5531 - val_accuracy: 0.7247\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7240 - val_loss: 0.5523 - val_accuracy: 0.7247\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5294 - accuracy: 0.7256 - val_loss: 0.5515 - val_accuracy: 0.7247\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7272 - val_loss: 0.5507 - val_accuracy: 0.7247\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7280 - val_loss: 0.5496 - val_accuracy: 0.7247\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.7312 - val_loss: 0.5490 - val_accuracy: 0.7247\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7328 - val_loss: 0.5484 - val_accuracy: 0.7247\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7335 - val_loss: 0.5479 - val_accuracy: 0.7310\n",
      "Epoch 47/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.7328 - val_loss: 0.5472 - val_accuracy: 0.7310\n",
      "Epoch 48/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7312 - val_loss: 0.5467 - val_accuracy: 0.7310\n",
      "Epoch 49/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.7320 - val_loss: 0.5462 - val_accuracy: 0.7373\n",
      "Epoch 50/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7351 - val_loss: 0.5460 - val_accuracy: 0.7405\n",
      "Epoch 51/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5227 - accuracy: 0.7351 - val_loss: 0.5455 - val_accuracy: 0.7437\n",
      "Epoch 52/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7343 - val_loss: 0.5451 - val_accuracy: 0.7468\n",
      "Epoch 53/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7351 - val_loss: 0.5447 - val_accuracy: 0.7437\n",
      "Epoch 54/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7343 - val_loss: 0.5442 - val_accuracy: 0.7437\n",
      "Epoch 55/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7367 - val_loss: 0.5439 - val_accuracy: 0.7468\n",
      "Epoch 56/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7367 - val_loss: 0.5437 - val_accuracy: 0.7468\n",
      "Epoch 57/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7399 - val_loss: 0.5435 - val_accuracy: 0.7468\n",
      "Epoch 58/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7391 - val_loss: 0.5433 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7423 - val_loss: 0.5428 - val_accuracy: 0.7468\n",
      "Epoch 60/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7415 - val_loss: 0.5429 - val_accuracy: 0.7500\n",
      "Epoch 61/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7415 - val_loss: 0.5426 - val_accuracy: 0.7500\n",
      "Epoch 62/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7407 - val_loss: 0.5425 - val_accuracy: 0.7500\n",
      "Epoch 63/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7407 - val_loss: 0.5424 - val_accuracy: 0.7532\n",
      "Epoch 64/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7407 - val_loss: 0.5421 - val_accuracy: 0.7532\n",
      "Epoch 65/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7423 - val_loss: 0.5421 - val_accuracy: 0.7532\n",
      "Epoch 66/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7415 - val_loss: 0.5420 - val_accuracy: 0.7532\n",
      "Epoch 67/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7415 - val_loss: 0.5418 - val_accuracy: 0.7532\n",
      "Epoch 68/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7446 - val_loss: 0.5418 - val_accuracy: 0.7532\n",
      "Epoch 69/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7454 - val_loss: 0.5415 - val_accuracy: 0.7532\n",
      "Epoch 70/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7439 - val_loss: 0.5415 - val_accuracy: 0.7532\n",
      "Epoch 71/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7431 - val_loss: 0.5413 - val_accuracy: 0.7532\n",
      "Epoch 72/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7423 - val_loss: 0.5412 - val_accuracy: 0.7532\n",
      "Epoch 73/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7446 - val_loss: 0.5411 - val_accuracy: 0.7500\n",
      "Epoch 74/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7431 - val_loss: 0.5410 - val_accuracy: 0.7500\n",
      "Epoch 75/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7439 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
      "Epoch 76/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7446 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
      "Epoch 77/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7454 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
      "Epoch 78/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7462 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
      "Epoch 79/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7454 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
      "Epoch 80/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7446 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
      "Epoch 81/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7446 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
      "Epoch 82/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7446 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
      "Epoch 83/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7439 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
      "Epoch 84/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7439 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
      "Epoch 85/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7407 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
      "Epoch 86/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7415 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
      "Epoch 87/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7407 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
      "Epoch 88/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7431 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
      "Epoch 89/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7431 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
      "Epoch 90/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7415 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
      "Epoch 91/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7415 - val_loss: 0.5397 - val_accuracy: 0.7468\n",
      "Epoch 92/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7415 - val_loss: 0.5398 - val_accuracy: 0.7468\n",
      "Epoch 93/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7423 - val_loss: 0.5397 - val_accuracy: 0.7468\n",
      "Epoch 94/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7415 - val_loss: 0.5397 - val_accuracy: 0.7468\n",
      "Epoch 95/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7407 - val_loss: 0.5396 - val_accuracy: 0.7468\n",
      "Epoch 96/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7407 - val_loss: 0.5394 - val_accuracy: 0.7468\n",
      "Epoch 97/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7415 - val_loss: 0.5395 - val_accuracy: 0.7468\n",
      "Epoch 98/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7415 - val_loss: 0.5394 - val_accuracy: 0.7468\n",
      "Epoch 99/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7407 - val_loss: 0.5391 - val_accuracy: 0.7468\n",
      "Epoch 100/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7399 - val_loss: 0.5392 - val_accuracy: 0.7468\n",
      "Epoch 101/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7407 - val_loss: 0.5392 - val_accuracy: 0.7468\n",
      "Epoch 102/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7407 - val_loss: 0.5393 - val_accuracy: 0.7468\n",
      "Epoch 103/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7407 - val_loss: 0.5393 - val_accuracy: 0.7468\n",
      "Epoch 104/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7415 - val_loss: 0.5391 - val_accuracy: 0.7468\n",
      "Epoch 105/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7399 - val_loss: 0.5391 - val_accuracy: 0.7468\n",
      "Epoch 106/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7399 - val_loss: 0.5393 - val_accuracy: 0.7468\n",
      "Epoch 107/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7415 - val_loss: 0.5392 - val_accuracy: 0.7468\n",
      "Epoch 108/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7415 - val_loss: 0.5390 - val_accuracy: 0.7468\n",
      "Epoch 109/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7415 - val_loss: 0.5391 - val_accuracy: 0.7468\n",
      "Epoch 110/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7399 - val_loss: 0.5389 - val_accuracy: 0.7468\n",
      "Epoch 111/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7407 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
      "Epoch 112/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7407 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 113/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7399 - val_loss: 0.5389 - val_accuracy: 0.7468\n",
      "Epoch 114/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7407 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 115/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7415 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7431 - val_loss: 0.5388 - val_accuracy: 0.7468\n",
      "Epoch 117/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7383 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
      "Epoch 118/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7415 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
      "Epoch 119/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7407 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 120/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7407 - val_loss: 0.5387 - val_accuracy: 0.7500\n",
      "Epoch 121/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7415 - val_loss: 0.5388 - val_accuracy: 0.7468\n",
      "Epoch 122/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7399 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 123/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7399 - val_loss: 0.5387 - val_accuracy: 0.7532\n",
      "Epoch 124/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7423 - val_loss: 0.5387 - val_accuracy: 0.7500\n",
      "Epoch 125/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7399 - val_loss: 0.5386 - val_accuracy: 0.7532\n",
      "Epoch 126/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7391 - val_loss: 0.5386 - val_accuracy: 0.7500\n",
      "Epoch 127/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7391 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
      "Epoch 128/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7359 - val_loss: 0.5387 - val_accuracy: 0.7500\n",
      "Epoch 129/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7399 - val_loss: 0.5389 - val_accuracy: 0.7532\n",
      "Epoch 130/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7399 - val_loss: 0.5388 - val_accuracy: 0.7532\n",
      "Epoch 131/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7399 - val_loss: 0.5388 - val_accuracy: 0.7532\n",
      "Epoch 132/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7383 - val_loss: 0.5389 - val_accuracy: 0.7532\n",
      "Epoch 133/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7423 - val_loss: 0.5385 - val_accuracy: 0.7532\n",
      "Epoch 134/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7391 - val_loss: 0.5384 - val_accuracy: 0.7532\n",
      "Epoch 135/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7391 - val_loss: 0.5384 - val_accuracy: 0.7532\n",
      "Epoch 136/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7375 - val_loss: 0.5385 - val_accuracy: 0.7532\n",
      "Epoch 137/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7383 - val_loss: 0.5386 - val_accuracy: 0.7532\n",
      "Epoch 138/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7383 - val_loss: 0.5386 - val_accuracy: 0.7532\n",
      "Epoch 139/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7383 - val_loss: 0.5385 - val_accuracy: 0.7532\n",
      "Epoch 140/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7399 - val_loss: 0.5384 - val_accuracy: 0.7532\n",
      "Epoch 141/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7399 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
      "Epoch 142/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7399 - val_loss: 0.5383 - val_accuracy: 0.7532\n",
      "Epoch 143/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7423 - val_loss: 0.5384 - val_accuracy: 0.7532\n",
      "Epoch 144/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7391 - val_loss: 0.5384 - val_accuracy: 0.7532\n",
      "Epoch 145/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7423 - val_loss: 0.5383 - val_accuracy: 0.7532\n",
      "Epoch 146/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7399 - val_loss: 0.5385 - val_accuracy: 0.7532\n",
      "Epoch 147/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7431 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
      "Epoch 148/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7415 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
      "Epoch 149/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7383 - val_loss: 0.5383 - val_accuracy: 0.7532\n",
      "Epoch 150/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7415 - val_loss: 0.5384 - val_accuracy: 0.7500\n",
      "Epoch 151/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7415 - val_loss: 0.5383 - val_accuracy: 0.7532\n",
      "Epoch 152/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7391 - val_loss: 0.5383 - val_accuracy: 0.7532\n",
      "Epoch 153/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7431 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
      "Epoch 154/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7399 - val_loss: 0.5384 - val_accuracy: 0.7532\n",
      "Epoch 155/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7431 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
      "Epoch 156/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7415 - val_loss: 0.5381 - val_accuracy: 0.7500\n",
      "Epoch 157/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7423 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
      "Epoch 158/200\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.5157 - accuracy: 0.7415 - val_loss: 0.5381 - val_accuracy: 0.7532\n",
      "Epoch 159/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7415 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
      "Epoch 160/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7399 - val_loss: 0.5382 - val_accuracy: 0.7532\n",
      "Epoch 161/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7399 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
      "Epoch 162/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7391 - val_loss: 0.5380 - val_accuracy: 0.7532\n",
      "Epoch 163/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7407 - val_loss: 0.5381 - val_accuracy: 0.7532\n",
      "Epoch 164/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7407 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
      "Epoch 165/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7391 - val_loss: 0.5379 - val_accuracy: 0.7532\n",
      "Epoch 166/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7391 - val_loss: 0.5379 - val_accuracy: 0.7500\n",
      "Epoch 167/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7415 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
      "Epoch 168/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7399 - val_loss: 0.5380 - val_accuracy: 0.7532\n",
      "Epoch 169/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7391 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
      "Epoch 170/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7407 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
      "Epoch 171/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7407 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
      "Epoch 172/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7399 - val_loss: 0.5379 - val_accuracy: 0.7500\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7383 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
      "Epoch 174/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7423 - val_loss: 0.5379 - val_accuracy: 0.7500\n",
      "Epoch 175/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7391 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
      "Epoch 176/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7375 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
      "Epoch 177/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7383 - val_loss: 0.5382 - val_accuracy: 0.7532\n",
      "Epoch 178/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7383 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
      "Epoch 179/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7383 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
      "Epoch 180/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7367 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
      "Epoch 181/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7407 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
      "Epoch 182/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7407 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
      "Epoch 183/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7399 - val_loss: 0.5383 - val_accuracy: 0.7532\n",
      "Epoch 184/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7407 - val_loss: 0.5384 - val_accuracy: 0.7500\n",
      "Epoch 185/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7399 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
      "Epoch 186/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7399 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
      "Epoch 187/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7391 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
      "Epoch 188/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7391 - val_loss: 0.5381 - val_accuracy: 0.7500\n",
      "Epoch 189/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7391 - val_loss: 0.5381 - val_accuracy: 0.7500\n",
      "Epoch 190/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7391 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
      "Epoch 191/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7399 - val_loss: 0.5381 - val_accuracy: 0.7500\n",
      "Epoch 192/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7407 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
      "Epoch 193/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7407 - val_loss: 0.5381 - val_accuracy: 0.7500\n",
      "Epoch 194/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7399 - val_loss: 0.5379 - val_accuracy: 0.7532\n",
      "Epoch 195/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7407 - val_loss: 0.5379 - val_accuracy: 0.7532\n",
      "Epoch 196/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7407 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
      "Epoch 197/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7399 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
      "Epoch 198/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7375 - val_loss: 0.5378 - val_accuracy: 0.7500\n",
      "Epoch 199/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7391 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
      "Epoch 200/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7367 - val_loss: 0.5379 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26ce01d3820>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential([Dense(1, activation='sigmoid')])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics='accuracy')\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c70f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f14638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
